{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a6f11a-9301-4c41-a517-29364374f777",
   "metadata": {},
   "source": [
    "# RIODatasetSceneGraph class\n",
    "* no use rio27!\n",
    "* only deal with training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8e85250-f8d9-466f-a6e3-287365d454cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import os\n",
    "import os.path\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import graphto3d.dataset.util as util\n",
    "from graphto3d.helpers.psutil import FreeMemLinux\n",
    "from graphto3d.helpers.util import normalize_box_params, denormalize_box_params, get_rotation\n",
    "from graphto3d.model.atlasnet import AE_AtlasNet\n",
    "\n",
    "os.chdir(\"/root/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9840b4ce-5a51-48fa-a7ba-8817482a6b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_AtlasNet(\n",
       "  (encoder): Sequential(\n",
       "    (0): PointNetfeat(\n",
       "      (stn): STN3d(\n",
       "        (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "        (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): PointGenCon(\n",
       "      (conv1): Conv1d(130, 130, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(130, 65, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(65, 32, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(32, 3, kernel_size=(1,), stride=(1,))\n",
       "      (th): Tanh()\n",
       "      (bn1): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading atlas model\n",
    "path2atlas = \"/root/graphto3d/experiments/atlasnet/model_70.pth\"\n",
    "saved_atlasnet_model = torch.load(path2atlas)\n",
    "point_ae = AE_AtlasNet(num_points=1024, bottleneck_size=128, nb_primitives=25)\n",
    "point_ae.load_state_dict(saved_atlasnet_model, strict=True)\n",
    "if torch.cuda.is_available():\n",
    "    point_ae = point_ae.cuda()\n",
    "point_ae.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b8d5a-21d9-47ae-9b73-7b14aa742289",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "012679b5-f7c1-46cf-abe0-6a55bc8f84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_points(filename, factor=1, filter_mask=False):\n",
    "    point_set, _, _, mask = util.read_ply(filename)\n",
    "    if filter_mask:\n",
    "        point_set = point_set[np.where(mask > 0)[0], :]\n",
    "    choice = np.random.choice(len(point_set), npoints * factor, replace=True)\n",
    "    point_set = point_set[choice, :]\n",
    "    if len(mask) > 0:\n",
    "        mask.shape = (mask.shape[0], 1)  # in place reshape\n",
    "        mask = mask[choice, :]\n",
    "        mask = torch.from_numpy(np.array(mask, dtype=np.uint8))\n",
    "    point_set = torch.from_numpy(point_set)\n",
    "    return point_set, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a9016456-0e8d-4adc-96e1-0014e7dc159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_tensor(p, params7=None, scale=False, center=True, rotation=False, scale_func='diag'):\n",
    "    \"\"\" Given a set of points of an object and (optionally) a oriented 3D box, normalize points\n",
    "\n",
    "    :param p: tensor of 3D pointset\n",
    "    :param params7: bounding box parameters [W, L, H, Cx, Cy, Cy, Z]\n",
    "    :param scale: boolean, if true apply scaling to pointset p according to scale_func\n",
    "    :param center: boolean, if true normalize the center of points to 0,0,0\n",
    "    :param rotation: boolean, if true rotate points based on the box rotation in param7\n",
    "    :param scale_func: string specifying the function used for scaling. 'diag' normalizes the diagonal to length 1.\n",
    "    'whl' sets each dimension to range [-1,1].\n",
    "    :return: the normalized tensor of 3D pointset\n",
    "    \"\"\"\n",
    "    if center:\n",
    "        if params7 is None:\n",
    "            # this is center of mass\n",
    "            mean = torch.mean(p, dim=0)\n",
    "        else:\n",
    "            # get center from box center if available\n",
    "            mean = torch.from_numpy(params7[3:6].astype(\"float32\"))\n",
    "        p -= mean.unsqueeze(0)\n",
    "    if rotation and params7 is not None:\n",
    "        p = (torch.from_numpy(get_rotation(-params7[-1], degree=False).astype(\"float32\")) @ p.T).T\n",
    "    if scale and params7 is not None:\n",
    "        # first if needed rotate to canonical rotation\n",
    "        # apply scaling\n",
    "        # if needed rotate back\n",
    "        if not rotation:\n",
    "            p = (torch.from_numpy(get_rotation(-params7[-1], degree=False).astype(\"float32\")) @ p.T).T\n",
    "        if scale_func == 'diag':\n",
    "            # OPTION 1: normalize diagonal = 1\n",
    "            norm2 = np.linalg.norm(params7[:3].astype(\"float32\"))\n",
    "            p /= norm2\n",
    "        elif scale_func == 'whl':\n",
    "            # OPTION 2: normalize each axis by H, W, L\n",
    "            norm2 = torch.from_numpy(params7[:3].astype(\"float32\")).reshape(1, 3)\n",
    "            min_p = p.min(0)[0]\n",
    "            p = ((p - min_p) / norm2) * 2. - 1.  # between -1 and 1 in all directions\n",
    "        elif scale_func == 'whl_after':\n",
    "            norm2 = p.max(0)[0] - p.min(0)[0]\n",
    "            min_p = p.min(0)[0]\n",
    "            p = ((p - min_p) / norm2) * 2. - 1.  # between -1 and 1 in all directions\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if not rotation:\n",
    "            p = (torch.from_numpy(get_rotation(params7[-1], degree=False).astype(\"float32\")) @ p.T).T\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eaae34fb-6874-4352-9f7e-0a2e0cb26e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_semseg(json_file):\n",
    "    \"\"\" Loads semantic segmentation from json file\n",
    "\n",
    "    :param json_file: path to file\n",
    "    :return: dict, that maps instance label to text semantic label\n",
    "    \"\"\"\n",
    "    instance2label = {}\n",
    "    with open(json_file, \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "        for segGroups in data['segGroups']:\n",
    "            instance2label[segGroups[\"id\"]] = segGroups[\"label\"].lower()\n",
    "    return instance2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29cf50-6e5b-43b1-9295-89bc8d5d515d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## \\_\\_init\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb2dc9-1906-4b8b-813d-c4c1f41e31c6",
   "metadata": {},
   "source": [
    "* inputs when trainining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c47d5173-9d43-46da-a2ff-1731a9707c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/root/graphto3d/GT\"\n",
    "root_3rscan = \"/root/dev/G3D/3RScan\"\n",
    "label_file = \"labels.instances.align.annotated.ply\"\n",
    "npoints = 1024\n",
    "split = 'train_scans'\n",
    "shuffle_objs = True\n",
    "use_points = False # False?? why??\n",
    "use_scene_rels = True\n",
    "with_changes = False\n",
    "vae_baseline = False # True if 'network_type' == 'sln'\n",
    "with_feats = True\n",
    "large = True\n",
    "atlas = point_ae\n",
    "seed=False\n",
    "use_splits = True\n",
    "use_rio27 = False\n",
    "use_canonical = True\n",
    "crop_floor = False # True일 때도 고려\n",
    "center_scene_to_floor = crop_floor # True일 때도 고려\n",
    "recompute_feats = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0c3ba383-02f6-44ef-b7aa-1ed84a62573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars in init function\n",
    "scale_func = 'diag'\n",
    "catfile = os.path.join(root, 'classes.txt')\n",
    "cat = {}\n",
    "data_augmentation = True\n",
    "data_len = None\n",
    "fm = FreeMemLinux('GB')\n",
    "padding = 0.2\n",
    "pass_scan_id = False\n",
    "class_choice = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c9f0b-ecf1-4b23-9c83-753d7caf5a64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "86a806ac-6747-4c17-aadb-09d44153a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship reading function (in the class)\n",
    "def read_relationship_json(json_file, box_json_file):\n",
    "    \"\"\" Reads from json files the relationship labels, objects and bounding boxes\n",
    "\n",
    "    :param json_file: file that stores the objects and relationships\n",
    "    :param box_json_file: file that stores the oriented 3D bounding box parameters\n",
    "    :return: three dicts, relationships, objects and boxes and scans\n",
    "    \"\"\"\n",
    "    rel = {}\n",
    "    objs = {}\n",
    "    tight_boxes = {}\n",
    "    scans = []\n",
    "\n",
    "    with open(box_json_file, \"r\") as read_file:\n",
    "        box_data = json.load(read_file)\n",
    "\n",
    "    with open(json_file, \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "        for scan in data['scans']:\n",
    "\n",
    "            relationships = []\n",
    "            for realationship in scan[\"relationships\"]:\n",
    "                realationship[2] -= 1\n",
    "                relationships.append(realationship)\n",
    "\n",
    "            # for every scan in rel json, we append the scan id\n",
    "            rel[scan[\"scan\"] + \"_\" + str(scan[\"split\"])] = relationships\n",
    "            scans.append(scan[\"scan\"] + \"_\" + str(scan[\"split\"]))\n",
    "\n",
    "            objects = {}\n",
    "            boxes = {}\n",
    "            for k, v in scan[\"objects\"].items():\n",
    "                objects[int(k)] = v\n",
    "                try:\n",
    "                    boxes[int(k)] = {}\n",
    "                    boxes[int(k)]['param7'] = box_data[scan[\"scan\"]][k][\"param7\"]\n",
    "                    boxes[int(k)]['param7'][6] = np.deg2rad(boxes[int(k)]['param7'][6])\n",
    "                    if use_canonical:\n",
    "                        if \"direction\" in box_data[scan[\"scan\"]][k].keys():\n",
    "                            boxes[int(k)]['direction'] = box_data[scan[\"scan\"]][k][\"direction\"]\n",
    "                        else:\n",
    "                            boxes[int(k)]['direction'] = 0\n",
    "                except:\n",
    "                    # probably box was not saved because there were 0 points in the instance!\n",
    "                    continue\n",
    "            objs[scan[\"scan\"] + \"_\" + str(scan[\"split\"])] = objects\n",
    "            tight_boxes[scan[\"scan\"] + \"_\" + str(scan[\"split\"])] = boxes\n",
    "    return (rel, objs, tight_boxes), scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8fd85a7-3c40-4b12-912c-0a7a1ea9242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_relationships(read_file):\n",
    "    \"\"\"load list of relationship labels\n",
    "\n",
    "    :param read_file: path of relationship list txt file\n",
    "    \"\"\"\n",
    "    relationships = []\n",
    "    with open(read_file, 'r') as f:\n",
    "        for line in f:\n",
    "            relationship = line.rstrip().lower()\n",
    "            relationships.append(relationship)\n",
    "    return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f2e92e9d-e92f-4ed6-86e3-e40503674709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitfile:  /root/graphto3d/GT/train_scans.txt\n",
      "first element of filelist:  7272e161-a01b-20f6-8b5a-0b97efeb6545\n",
      "rel_json_file:  /root/graphto3d/GT/relationships_train_clean.json\n",
      "box_json_file:  /root/graphto3d/GT/obj_boxes_train_refined.json\n",
      "floor_json_file:  /root/graphto3d/GT/floor_boxes_split_train.json\n"
     ]
    }
   ],
   "source": [
    "# Load class and relationships\n",
    "vocab = {}\n",
    "with open(os.path.join(root, 'classes.txt'), \"r\") as f:\n",
    "    vocab['object_idx_to_name'] = f.readlines()\n",
    "with open(os.path.join(root, 'relationships.txt'), \"r\") as f:\n",
    "    vocab['pred_idx_to_name'] = f.readlines()\n",
    "\n",
    "# Load scan_id for training\n",
    "splitfile = os.path.join(root, '{}.txt'.format(split)) # split : 'train_scans'\n",
    "filelist = open(splitfile, \"r\").read().splitlines()\n",
    "\n",
    "print(\"splitfile: \", splitfile)\n",
    "print(\"first element of filelist: \", filelist[0]) # 3rscan folder name\n",
    "\n",
    "# assign fname according to training set or validation set\n",
    "if split == 'train_scans': # training set\n",
    "    splits_fname = 'relationships_train_clean' if use_splits else 'relationships_merged_train_clean'\n",
    "    rel_json_file = os.path.join(root, '{}.json'.format(splits_fname))\n",
    "    box_json_file = os.path.join(root, 'obj_boxes_train_refined.json')\n",
    "    floor_json_file = os.path.join(root, 'floor_boxes_split_train.json')\n",
    "else: # validation set\n",
    "    splits_fname = 'relationships_validation_clean' if use_splits else 'relationships_merged_validation_clean'\n",
    "    rel_json_file = os.path.join(root, '{}.json'.format(splits_fname))\n",
    "    box_json_file = os.path.join(root, 'obj_boxes_val_refined.json')\n",
    "    floor_json_file = os.path.join(root, 'floor_boxes_split_val.json')\n",
    "\n",
    "print(\"rel_json_file: \", rel_json_file)\n",
    "print(\"box_json_file: \", box_json_file)\n",
    "print(\"floor_json_file: \", floor_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1f72da8d-3c42-4246-aa21-539814109c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_floor is setted to False\n"
     ]
    }
   ],
   "source": [
    "# load floor-cropped data\n",
    "if crop_floor:\n",
    "    with open(floor_json_file, \"r\") as read_file:\n",
    "        floor_data = json.load(read_file)\n",
    "else:\n",
    "    print(\"crop_floor is setted to {}\".format(crop_floor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1db45e90-5d13-4310-978e-c53e6ba3091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relationships, objs, bboxes\n",
    "jsonlist, scans = read_relationship_json(rel_json_file, box_json_file)\n",
    "relationship_json, objs_json, tight_boxes_json = jsonlist[0], jsonlist[1], jsonlist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "19d56994-d7d0-4205-98f3-5bed513cea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the relationship_json file:\n",
      "first key of relationship_json file: f62fd5fd-9a3f-2f44-883a-1e5cf819608e_1\n",
      "first value of relationship_json file: [\n",
      "    4,\n",
      "    1,\n",
      "    13,\n",
      "    \"attached to\"\n",
      "]\n",
      "\n",
      "for the objs_json file:\n",
      "first key of objs_json file: f62fd5fd-9a3f-2f44-883a-1e5cf819608e_1\n",
      "value of objs_json file: {\n",
      "    \"1\": \"floor\",\n",
      "    \"26\": \"wall\",\n",
      "    \"25\": \"lamp\",\n",
      "    \"13\": \"cabinet\",\n",
      "    \"4\": \"wall\",\n",
      "    \"42\": \"stool\",\n",
      "    \"44\": \"pillow\",\n",
      "    \"14\": \"cabinet\",\n",
      "    \"15\": \"cabinet\"\n",
      "}\n",
      "\n",
      "for the tight_boxes_json file:\n",
      "first key of tight_boxes_json file: f62fd5fd-9a3f-2f44-883a-1e5cf819608e_1\n",
      "value of tight_boxes_json file: {\n",
      "    \"1\": {\n",
      "        \"param7\": [\n",
      "            8.300434079221413,\n",
      "            4.541183126091166,\n",
      "            0.22766995429992676,\n",
      "            0.9669842840141765,\n",
      "            0.13836722910367122,\n",
      "            -1.4374949932098389,\n",
      "            1.8938213499224684e-09\n",
      "        ],\n",
      "        \"direction\": 2\n",
      "    },\n",
      "    \"26\": {\n",
      "        \"param7\": [\n",
      "            0.3735505047342036,\n",
      "            0.8817548283293477,\n",
      "            1.3200799971818924,\n",
      "            4.119918342495633,\n",
      "            2.861250760709597,\n",
      "            -0.8300400003790855,\n",
      "            0.5934119456780721\n",
      "        ],\n",
      "        \"direction\": 1\n",
      "    },\n",
      "    \"25\": {\n",
      "        \"param7\": [\n",
      "            0.6285723063301507,\n",
      "            0.46238979589508344,\n",
      "            0.9963950216770172,\n",
      "            2.280402429504929,\n",
      "            1.8927481405112294,\n",
      "            -0.9718025177717209,\n",
      "            0.9773843811168246\n",
      "        ],\n",
      "        \"direction\": 2\n",
      "    },\n",
      "    \"13\": {\n",
      "        \"param7\": [\n",
      "            0.6856988192802402,\n",
      "            0.22966141395320472,\n",
      "            0.8951100707054138,\n",
      "            3.0773002909301272,\n",
      "            0.9110344308451378,\n",
      "            -1.0375550091266632,\n",
      "            1.239183768915974\n",
      "        ],\n",
      "        \"direction\": 2\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"param7\": [\n",
      "            0.23987385317924215,\n",
      "            3.142567721571843,\n",
      "            2.63742995262146,\n",
      "            1.1864435140784948,\n",
      "            2.5389244516877127,\n",
      "            -0.16220498085021973,\n",
      "            1.2566370614359172\n",
      "        ],\n",
      "        \"direction\": 1\n",
      "    },\n",
      "    \"42\": {\n",
      "        \"param7\": [\n",
      "            0.4791344689217656,\n",
      "            0.4482046408830894,\n",
      "            0.4252300262451172,\n",
      "            2.069303897020833,\n",
      "            1.5752286433109455,\n",
      "            -1.2626149654388428,\n",
      "            0.20943951023931956\n",
      "        ],\n",
      "        \"direction\": 5\n",
      "    },\n",
      "    \"44\": {\n",
      "        \"param7\": [\n",
      "            0.4248330621410088,\n",
      "            0.48589803144503374,\n",
      "            0.3799999952316284,\n",
      "            1.5764941182461052,\n",
      "            1.957273349241838,\n",
      "            -0.9200000166893005,\n",
      "            1.3264502315156905\n",
      "        ],\n",
      "        \"direction\": 1\n",
      "    },\n",
      "    \"14\": {\n",
      "        \"param7\": [\n",
      "            0.27362502866388594,\n",
      "            2.618827213335212,\n",
      "            0.6138310134410858,\n",
      "            0.9594329760732269,\n",
      "            2.462103404652306,\n",
      "            0.03691549599170685,\n",
      "            1.1868238913561442\n",
      "        ],\n",
      "        \"direction\": 3\n",
      "    },\n",
      "    \"15\": {\n",
      "        \"param7\": [\n",
      "            0.170733917990868,\n",
      "            2.464876912476978,\n",
      "            0.6805109977722168,\n",
      "            0.9688902636358825,\n",
      "            2.251911626190039,\n",
      "            0.5958315134048462,\n",
      "            1.2217304763960306\n",
      "        ],\n",
      "        \"direction\": 3\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "jsonlist = [relationship_json, objs_json, tight_boxes_json]\n",
    "fnamelist = ['relationship_json', 'objs_json', 'tight_boxes_json']\n",
    "\n",
    "for i in range(len(jsonlist)):\n",
    "    print(\"for the {} file:\".format(fnamelist[i]))\n",
    "    tmp = list(jsonlist[i].keys())[0]\n",
    "    print(\"first key of {} file: {}\".format(fnamelist[i], tmp))\n",
    "    if str(type(jsonlist[i][tmp])) == \"<class 'list'>\":\n",
    "        print(\"first value of {} file: {}\".format(fnamelist[i], json.dumps(jsonlist[i][tmp][0], indent=4)))\n",
    "        print()\n",
    "    else:\n",
    "        print(\"value of {} file: {}\".format(fnamelist[i], json.dumps(jsonlist[i][tmp], indent=4)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06051f-b452-4ba8-ab0f-913b414aa7af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3487d7-7f8e-4c37-a608-f18e173cc3a4",
   "metadata": {},
   "source": [
    "* classes with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "444b83be-40aa-4190-a36e-6bb8557f7ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th element in cat -> \"_scene_\" : \"_scene_\"\n",
      "1th element in cat -> \"armchair\" : \"armchair\"\n",
      "2th element in cat -> \"backpack\" : \"backpack\"\n",
      "3th element in cat -> \"bag\" : \"bag\"\n",
      "4th element in cat -> \"ball\" : \"ball\"\n",
      "5th element in cat -> \"bar\" : \"bar\"\n",
      "number of elements in cat:  161\n",
      "\n",
      "classes:\n",
      " {'_scene_': 0, 'armchair': 1, 'backpack': 2, 'bag': 3, 'ball': 4, 'bar': 5, 'basin': 6, 'basket': 7, 'bath cabinet': 8, 'bathtub': 9, 'bed': 10, 'bedside table': 11, 'bench': 12, 'bidet': 13, 'bin': 14, 'blanket': 15, 'blinds': 16, 'board': 17, 'book': 18, 'books': 19, 'bookshelf': 20, 'bottle': 21, 'box': 22, 'bread': 23, 'bucket': 24, 'cabinet': 25, 'carpet': 26, 'ceiling': 27, 'chair': 28, 'cleanser': 29, 'clock': 30, 'closet': 31, 'clothes': 32, 'clothes dryer': 33, 'clutter': 34, 'coffee machine': 35, 'coffee table': 36, 'commode': 37, 'computer desk': 38, 'couch': 39, 'couch table': 40, 'counter': 41, 'cup': 42, 'cupboard': 43, 'curtain': 44, 'cushion': 45, 'cutting board': 46, 'decoration': 47, 'desk': 48, 'dining chair': 49, 'dining table': 50, 'door': 51, 'doorframe': 52, 'drawer': 53, 'drum': 54, 'drying machine': 55, 'extractor fan': 56, 'fireplace': 57, 'floor': 58, 'flower': 59, 'flowers': 60, 'folder': 61, 'food': 62, 'footstool': 63, 'frame': 64, 'fruit plate': 65, 'garbage': 66, 'garbage bin': 67, 'grass': 68, 'hand dryer': 69, 'heater': 70, 'item': 71, 'jacket': 72, 'jar': 73, 'kettle': 74, 'kitchen appliance': 75, 'kitchen cabinet': 76, 'kitchen counter': 77, 'kitchen hood': 78, 'ladder': 79, 'lamp': 80, 'laptop': 81, 'laundry basket': 82, 'light': 83, 'machine': 84, 'magazine rack': 85, 'menu': 86, 'microwave': 87, 'mirror': 88, 'monitor': 89, 'napkins': 90, 'nightstand': 91, 'object': 92, 'objects': 93, 'organizer': 94, 'ottoman': 95, 'oven': 96, 'pack': 97, 'pan': 98, 'paper towel': 99, 'papers': 100, 'pc': 101, 'picture': 102, 'pile of books': 103, 'pile of papers': 104, 'pillow': 105, 'pipe': 106, 'plant': 107, 'plate': 108, 'player': 109, 'pot': 110, 'printer': 111, 'rack': 112, 'radiator': 113, 'recycle bin': 114, 'refrigerator': 115, 'rocking chair': 116, 'scale': 117, 'screen': 118, 'shelf': 119, 'shoe': 120, 'shoe rack': 121, 'shoes': 122, 'showcase': 123, 'shower': 124, 'shower curtain': 125, 'shower floor': 126, 'shower wall': 127, 'side table': 128, 'sink': 129, 'soap dish': 130, 'socket': 131, 'sofa': 132, 'sofa chair': 133, 'stair': 134, 'stand': 135, 'stool': 136, 'stove': 137, 'stuffed animal': 138, 'suitcase': 139, 'table': 140, 'table lamp': 141, 'telephone': 142, 'toaster': 143, 'toilet': 144, 'toilet brush': 145, 'toilet paper': 146, 'toilet paper dispenser': 147, 'towel': 148, 'trash can': 149, 'trashcan': 150, 'tube': 151, 'tv': 152, 'tv stand': 153, 'vase': 154, 'wall': 155, 'wardrobe': 156, 'washing machine': 157, 'washing powder': 158, 'window': 159, 'windowsill': 160}\n"
     ]
    }
   ],
   "source": [
    "# set the classes with categories\n",
    "with open(catfile, 'r') as f:\n",
    "    for line in f:\n",
    "        category = line.rstrip()\n",
    "        cat[category] = category\n",
    "if not class_choice is None:\n",
    "    cat = {k: v for k, v in cat.items() if k in class_choice}\n",
    "\n",
    "count = 0\n",
    "for key in cat.keys():\n",
    "    print('{}th element in cat -> \"{}\" : \"{}\"'.format(count, key, cat[key]))\n",
    "    count += 1\n",
    "    if count > 5: break\n",
    "print(\"number of elements in cat: \", len(cat))\n",
    "print()\n",
    "\n",
    "# classes\n",
    "classes = dict(zip(sorted(cat), range(len(cat))))\n",
    "print('classes:\\n', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86846f36-e0d3-4df8-aa89-591424286533",
   "metadata": {},
   "source": [
    "* points_classes_idx\n",
    "    * Discard some underrepresented classes for the shape generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "86292555-7585-42a8-8f17-e45e0af9827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points_classes_idx:  [4, 7, 12, 10, 22, 25, 28, 1, 48, 51, 58, 102, 132, 39, 37, 89, 136, 152, 140]\n",
      "\n",
      "classes corresponding to points_classes_idx:\n",
      " ['ball', 'basket', 'bench', 'bed', 'box', 'cabinet', 'chair', 'armchair', 'desk', 'door', 'floor', 'picture', 'sofa', 'couch', 'commode', 'monitor', 'stool', 'tv', 'table']\n"
     ]
    }
   ],
   "source": [
    "if not large:\n",
    "    points_classes = ['bed', 'chair', 'armchair', 'desk', 'door', 'floor', 'picture', 'sofa', 'couch',\n",
    "                      'stool', 'table']\n",
    "else: # larger set of shape classes\n",
    "    points_classes = ['ball', 'basket', 'bench', 'bed', 'box', 'cabinet', 'chair', 'armchair',\n",
    "                      'desk', 'door', 'floor', 'picture', 'sofa', 'couch', 'commode', 'monitor',\n",
    "                      'stool', 'tv', 'table']\n",
    "\n",
    "points_classes_idx = []\n",
    "for pc in points_classes:\n",
    "    if class_choice is not None:\n",
    "        if pc in classes:\n",
    "            points_classes_idx.append(classes[pc])\n",
    "        else:\n",
    "            points_classes_idx.append(0)\n",
    "    else:\n",
    "        if not use_rio27:\n",
    "            points_classes_idx.append(classes[pc])\n",
    "        else:\n",
    "            points_classes_idx.append(int(vocab_rio27['rio27_name_to_idx'][pc]))\n",
    "\n",
    "print('points_classes_idx: ', points_classes_idx)\n",
    "print()\n",
    "\n",
    "classlist = []\n",
    "for idx in points_classes_idx:\n",
    "    for key in classes.keys():\n",
    "        if classes[key] == idx:\n",
    "            classlist.append(key)\n",
    "print('classes corresponding to points_classes_idx:\\n', classlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a5ad0f-d723-413b-94f0-3021fabb3c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## \\_\\_getitem\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc9c40-9029-4820-8a91-cd69298d0a58",
   "metadata": {},
   "source": [
    "* input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dd810d11-d1e5-4b26-92e7-6795cf531644",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c923c-a4a8-42b3-9887-ce4d5914a6f6",
   "metadata": {},
   "source": [
    "* scan id, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e41d014b-a8ab-4c3d-b7e1-8b19c0e6d3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan_id: f62fd5fd-9a3f-2f44-883a-1e5cf819608e_1\n",
      "scan_id_no_split: f62fd5fd-9a3f-2f44-883a-1e5cf819608e\n",
      "split: 1\n"
     ]
    }
   ],
   "source": [
    "scan_id = scans[index]\n",
    "\n",
    "scan_id_no_split = scan_id.split('_')[0]\n",
    "split = scan_id.split('_')[1]\n",
    "\n",
    "print('scan_id:', scan_id)\n",
    "print('scan_id_no_split:', scan_id_no_split)\n",
    "print('split:', split)\n",
    "\n",
    "# if crop_floor is true, save floor index and set the center of the scene\n",
    "if crop_floor:\n",
    "    scene_floor = floor_data[scan_id_no_split][split]\n",
    "    floor_idx = list(scene_floor.keys())[0]\n",
    "    if center_scene_to_floor:\n",
    "        scene_center = np.asarray(scene_floor[floor_idx]['params7'][3:6])\n",
    "    else:\n",
    "        scene_center = np.array([0, 0, 0])\n",
    "\n",
    "    min_box = np.asarray(scene_floor[floor_idx]['min_box']) - scene_center\n",
    "    max_box = np.asarray(scene_floor[floor_idx]['max_box']) - scene_center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd67d4-07e5-4984-b405-10d0b323c65f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get semseg of the scene from 3RScan data\n",
    "* instance2label : A dictionary loaded from 3RScan data (id : label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9b47c47a-6f94-4ed4-9a27-fa2598955b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/dev/G3D/3RScan/f62fd5fd-9a3f-2f44-883a-1e5cf819608e/semseg.v2.json\n"
     ]
    }
   ],
   "source": [
    "file = os.path.join(root_3rscan, scan_id_no_split, label_file)\n",
    "if os.path.exists(os.path.join(root_3rscan, scan_id_no_split, \"semseg.v2.json\")):\n",
    "    semseg_file = os.path.join(root_3rscan, scan_id_no_split, \"semseg.v2.json\")\n",
    "elif os.path.exists(os.path.join(root_3rscan, scan_id_no_split, \"semseg.json\")):\n",
    "    semseg_file = os.path.join(root_3rscan, scan_id_no_split, \"semseg.json\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Cannot find semseg.json file.\")\n",
    "\n",
    "print(semseg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "834d1c04-2692-42b3-8807-b48564512eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance2label:  {20: 'chair', 21: 'chair', 22: 'kitchen cabinet', 23: 'kitchen counter', 24: 'wall', 1: 'floor', 2: 'sofa', 3: 'sofa couch', 4: 'wall', 5: 'wall', 6: 'blinds', 7: 'blinds', 8: 'table', 9: 'wall', 11: 'cabinet', 12: 'cabinet', 13: 'cabinet', 14: 'cabinet', 15: 'cabinet', 16: 'wall', 17: 'curtain', 18: 'cabinet', 19: 'chair', 25: 'lamp', 26: 'wall', 27: 'chair', 28: 'wall', 29: 'plant', 30: 'lamp', 33: 'stool', 34: 'chair', 35: 'chair', 36: 'chair', 38: 'tv', 39: 'lamp', 40: 'curtain', 41: 'curtain', 42: 'stool', 43: 'pillow', 44: 'pillow', 45: 'pillow', 46: 'pillow', 47: 'pillow', 48: 'pillow', 49: 'pillow', 50: 'pillow', 52: 'pillow', 53: 'item', 54: 'item', 55: 'sink', 56: 'plant', 57: 'box', 58: 'book', 59: 'knife box', 60: 'pepper', 61: 'blinds', 62: 'blinds', 63: 'curtain', 64: 'lamp', 76: 'lamp'}\n",
      "\n",
      "objs_json of the scene:  {1: 'floor', 26: 'wall', 25: 'lamp', 13: 'cabinet', 4: 'wall', 42: 'stool', 44: 'pillow', 14: 'cabinet', 15: 'cabinet'}\n",
      "\n",
      "selected_instances:  [1, 26, 25, 13, 4, 42, 44, 14, 15]\n",
      "\n",
      "keys:  [20, 21, 22, 23, 24, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 76]\n"
     ]
    }
   ],
   "source": [
    "instance2label = load_semseg(semseg_file)\n",
    "selected_instances = list(objs_json[scan_id].keys())\n",
    "keys = list(instance2label.keys())\n",
    "\n",
    "print('instance2label: ', instance2label)\n",
    "print('\\nobjs_json of the scene: ', objs_json[scan_id])\n",
    "print('\\nselected_instances: ', selected_instances)\n",
    "print('\\nkeys: ', keys)\n",
    "\n",
    "if shuffle_objs:\n",
    "    random.shuffle(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969dc18-7e68-44e9-98e2-bdcb9d777f97",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare for loading the features (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ba198a72-c545-4783-8592-be8dfd391b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlasname:  model_70\n",
      "feats_path:  /root/dev/G3D/3RScan/f62fd5fd-9a3f-2f44-883a-1e5cf819608e/model_70_large_splits_1.pkl\n"
     ]
    }
   ],
   "source": [
    "feats_in = None\n",
    "\n",
    "# if true, expected paths to saved atlasnet features will be set here\n",
    "if with_feats and path2atlas is not None:\n",
    "    _, atlasname = os.path.split(path2atlas)\n",
    "    atlasname = atlasname.split('.')[0]\n",
    "    print('atlasname: ', atlasname)\n",
    "    \n",
    "    if not large:\n",
    "        feats_path = os.path.join(root_3rscan, scan_id.split('_')[0],\n",
    "                                 '{}_small_{}_{}.pkl'.format(atlasname,\n",
    "                                                            'splits' if use_splits else 'merged',\n",
    "                                                            scan_id.split('_')[1]))\n",
    "    else:\n",
    "        feats_path = os.path.join(root_3rscan, scan_id.split('_')[0],\n",
    "                                 '{}_large_{}_{}.pkl'.format(atlasname,\n",
    "                                                            'splits' if use_splits else 'merged',\n",
    "                                                            scan_id.split('_')[1]))\n",
    "        if crop_floor:\n",
    "            feats_path = os.path.join(root_3rscan, scan_id.split('_')[0],\n",
    "                                 '{}_large_{}_{}_floor.pkl'.format(atlasname,\n",
    "                                                                   'splits' if use_splits else 'merged',\n",
    "                                                                   scan_id.split('_')[1]))\n",
    "    if recompute_feats:\n",
    "        feats_path += 'tmp'\n",
    "\n",
    "print('feats_path: ', feats_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3feeec5-c0be-4122-afa1-5fe1015aaca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load points\n",
    "* keys : keys of instance2label (id of instances)\n",
    "* classes : total obj classes in 3RScan {'label' : id}\n",
    "* selected_instances : object ids in the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ed1259a7-1b4f-42a4-afa5-0dda6a8fea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "\n",
    "if (with_feats and (not os.path.exists(feats_path) or recompute_feats)) or use_points:\n",
    "    if file in files: # Caching\n",
    "        (points, instances) = files[file]\n",
    "    else:\n",
    "        points, instances, _, _ = util.read_ply(file) # gets only objectId, not a globalId\n",
    "\n",
    "        if fm.user_free > 5:\n",
    "            files[file] = (points, instances)\n",
    "\n",
    "    if crop_floor and center_scene_to_floor:\n",
    "        print(\"shifting points\")\n",
    "        points = points - scene_center.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832b4cc-8bfc-481f-a196-08c232734a51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get objects from the selected list of classes of 3DSSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6c23b9a3-c85a-494b-bc35-ddd3f6afced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 wall\n",
      "instance2mask: {0: 0, 24: 0}\n",
      "3 sofa couch\n",
      "instance2mask: {0: 0, 24: 0, 3: 0}\n",
      "44 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1}\n",
      "cat: [105]\n",
      "instances_order: [44]\n",
      "50 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0}\n",
      "16 wall\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0}\n",
      "13 cabinet\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2}\n",
      "cat: [105, 25]\n",
      "instances_order: [44, 13]\n",
      "27 chair\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0}\n",
      "22 kitchen cabinet\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0}\n",
      "62 blinds\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0}\n",
      "29 plant\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0}\n",
      "46 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0}\n",
      "53 item\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0}\n",
      "35 chair\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0}\n",
      "5 wall\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0}\n",
      "59 knife box\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0}\n",
      "1 floor\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3}\n",
      "cat: [105, 25, 58]\n",
      "instances_order: [44, 13, 1]\n",
      "25 lamp\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4}\n",
      "cat: [105, 25, 58, 80]\n",
      "instances_order: [44, 13, 1, 25]\n",
      "7 blinds\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0}\n",
      "2 sofa\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0}\n",
      "8 table\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0}\n",
      "14 cabinet\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5}\n",
      "cat: [105, 25, 58, 80, 25]\n",
      "instances_order: [44, 13, 1, 25, 14]\n",
      "28 wall\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0}\n",
      "45 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0}\n",
      "17 curtain\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0}\n",
      "18 cabinet\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0}\n",
      "11 cabinet\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0}\n",
      "64 lamp\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0}\n",
      "21 chair\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0}\n",
      "36 chair\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0}\n",
      "49 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0}\n",
      "26 wall\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6}\n",
      "cat: [105, 25, 58, 80, 25, 155]\n",
      "instances_order: [44, 13, 1, 25, 14, 26]\n",
      "58 book\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0}\n",
      "20 chair\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0}\n",
      "48 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0}\n",
      "55 sink\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0}\n",
      "12 cabinet\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0}\n",
      "42 stool\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7}\n",
      "cat: [105, 25, 58, 80, 25, 155, 136]\n",
      "instances_order: [44, 13, 1, 25, 14, 26, 42]\n",
      "52 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0}\n",
      "63 curtain\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0}\n",
      "43 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0}\n",
      "61 blinds\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0}\n",
      "40 curtain\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0}\n",
      "34 chair\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0}\n",
      "57 box\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0}\n",
      "9 wall\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0}\n",
      "4 wall\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8}\n",
      "cat: [105, 25, 58, 80, 25, 155, 136, 155]\n",
      "instances_order: [44, 13, 1, 25, 14, 26, 42, 4]\n",
      "39 lamp\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0}\n",
      "60 pepper\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0}\n",
      "30 lamp\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0}\n",
      "15 cabinet\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9}\n",
      "cat: [105, 25, 58, 80, 25, 155, 136, 155, 25]\n",
      "instances_order: [44, 13, 1, 25, 14, 26, 42, 4, 15]\n",
      "33 stool\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0}\n",
      "19 chair\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0}\n",
      "38 tv\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0}\n",
      "41 curtain\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0, 41: 0}\n",
      "56 plant\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0, 41: 0, 56: 0}\n",
      "76 lamp\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0, 41: 0, 56: 0, 76: 0}\n",
      "23 kitchen counter\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0, 41: 0, 56: 0, 76: 0, 23: 0}\n",
      "47 pillow\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0, 41: 0, 56: 0, 76: 0, 23: 0, 47: 0}\n",
      "54 item\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0, 41: 0, 56: 0, 76: 0, 23: 0, 47: 0, 54: 0}\n",
      "6 blinds\n",
      "instance2mask: {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0, 41: 0, 56: 0, 76: 0, 23: 0, 47: 0, 54: 0, 6: 0}\n"
     ]
    }
   ],
   "source": [
    "instance2mask = {}\n",
    "instance2mask[0] = 0\n",
    "\n",
    "cat = []\n",
    "tight_boxes = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "instances_order = []\n",
    "selected_shapes = []\n",
    "\n",
    "# print('classes: ', classes)\n",
    "# print('selected_instances:', selected_instances)\n",
    "# print('keys:', keys)\n",
    "for key in keys: # keys : keys of instance2label\n",
    "    scene_instance_id = key\n",
    "    scene_instance_class = instance2label[key]\n",
    "    print(scene_instance_id, scene_instance_class)\n",
    "    scene_class_id = -1\n",
    "    if scene_instance_class in classes:\n",
    "        scene_class_id = classes[scene_instance_class]\n",
    "    \n",
    "    # add an dictionary element to instance2mask\n",
    "    if scene_class_id != -1 and key in selected_instances:\n",
    "        instance2mask[scene_instance_id] = counter + 1\n",
    "        counter += 1\n",
    "    else:\n",
    "        instance2mask[scene_instance_id] = 0\n",
    "    print('instance2mask:', instance2mask)\n",
    "    \n",
    "    # mask to cat\n",
    "    if (scene_class_id >= 0) and (scene_instance_id > 0) and (key in selected_instances): # for the object in the scene\n",
    "        # cat\n",
    "        if use_canonical:\n",
    "            direction = tight_boxes_json[scan_id][key]['direction']\n",
    "            if direction in [-1, 0, 6]:\n",
    "                # skip invalid point clouds with ambiguous direction annotation\n",
    "                selected_shapes.append(False)\n",
    "            else:\n",
    "                selected_shapes.append(True)\n",
    "        cat.append(scene_class_id)\n",
    "        print('cat:', cat)\n",
    "        bbox = tight_boxes_json[scan_id][key]['param7'].copy()\n",
    "        if crop_floor and key in floor_data[scan_id_no_split][split].keys(): # for the floor\n",
    "            bbox = floor_data[scan_id_no_split][split][key]['params7'].copy()\n",
    "            bbox[6] = np.deg2rad(bbox[6]) # rotation of the floor bbox\n",
    "            direction = floor_data[scan_id_no_split][split][key]['direction']\n",
    "        \n",
    "        # instances_order\n",
    "        if use_canonical:\n",
    "            if direction > 1 and direction < 5:\n",
    "                # update direction-less angle with direction data (shifs it by 90 degree\n",
    "                # for every added direction value)\n",
    "                bbox[6] += (direction - 1) * np.deg2rad(90)\n",
    "                if direction == 2 or direction == 4:\n",
    "                    temp = bbox[0]\n",
    "                    bbox[0] = bbox[1]\n",
    "                    bbox[1] = temp\n",
    "            # for other options, do not change the box\n",
    "        instances_order.append(key)\n",
    "        print('instances_order:', instances_order)\n",
    "        \n",
    "        # tight_boxes\n",
    "        if not vae_baseline:\n",
    "            bins = np.linspace(0, np.deg2rad(360), 24)\n",
    "            angle = np.digitize(bbox[6], bins)\n",
    "            bbox = normalize_box_params(bbox)\n",
    "        else:\n",
    "            bins = np.linspace(0, np.deg2rad(360), 24)\n",
    "            bbox[6] = np.digitize(bbox[6], bins)\n",
    "        tight_boxes.append(bbox)\n",
    "        # print(tight_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667c318-6e77-43fd-9aa8-7076d897f92e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### If precomputed features exist, simply load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1b3d0d30-08d0-4b67-a8d8-7861ac541b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128) \n",
      " [[0.4360339  1.1080422  0.         ... 0.         0.02795782 0.47313926]\n",
      " [0.4360339  1.1080422  0.         ... 0.         0.02795782 0.47313926]\n",
      " [0.4360339  1.1080422  0.         ... 0.         0.02795782 0.47313926]\n",
      " ...\n",
      " [0.4360339  1.1080422  0.         ... 0.         0.02795782 0.47313926]\n",
      " [0.33617944 0.2669381  0.11628396 ... 0.         0.20880023 0.22970316]\n",
      " [0.4360339  1.1080422  0.         ... 0.         0.02795782 0.47313926]] \n",
      "\n",
      "feats_order:  [ 4 26 14 13  1 25 44 42 15]\n",
      "instances_order:  [44, 13, 1, 25, 14, 26, 42, 4, 15]\n",
      "\n",
      "44\n",
      "[False False False False False False  True False False]\n",
      "13\n",
      "[False False False  True False False False False False]\n",
      "1\n",
      "[False False False False  True False False False False]\n",
      "25\n",
      "[False False False False False  True False False False]\n",
      "14\n",
      "[False False  True False False False False False False]\n",
      "26\n",
      "[False  True False False False False False False False]\n",
      "42\n",
      "[False False False False False False False  True False]\n",
      "4\n",
      "[ True False False False False False False False False]\n",
      "15\n",
      "[False False False False False False False False  True]\n",
      "(9, 1, 128)\n",
      "(10, 1, 128)\n",
      "(10, 128)\n"
     ]
    }
   ],
   "source": [
    "if with_feats:\n",
    "    if os.path.exists(feats_path):\n",
    "        feats_dic = pickle.load(open(feats_path, 'rb'))\n",
    "        \n",
    "        feats_in = feats_dic['feats']\n",
    "        print(feats_in.shape, '\\n', feats_in, '\\n')\n",
    "        feats_order = np.asarray(feats_dic['instance_order'])\n",
    "        print('feats_order: ', feats_order)\n",
    "        print('instances_order: ', instances_order)\n",
    "        print()\n",
    "        \n",
    "        ordered_feats = [] # ordered features wrt instances_order\n",
    "        for inst in instances_order:\n",
    "            feats_in_instance = inst == feats_order\n",
    "            print(inst)\n",
    "            print(feats_in_instance)\n",
    "            ordered_feats.append(feats_in[:-1][feats_in_instance])\n",
    "            # [:-1] → drop last index\n",
    "            # [feats_in_instance] → select feature(1, 128) for only true index\n",
    "        print(np.array(ordered_feats).shape)\n",
    "        ordered_feats.append(np.zeros([1, feats_in.shape[1]])) # (10, 1, 128)\n",
    "        print(np.array(ordered_feats).shape)\n",
    "        feats_in = list(np.concatenate(ordered_feats, axis=0)) # (10, 128)\n",
    "        print(np.array(feats_in).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1706e087-1f1f-41f3-a36e-d2ebe85fe34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) \n",
      " [[1 2]\n",
      " [2 3]\n",
      " [3 4]\n",
      " [4 5]]\n",
      "\n",
      "(3, 2) \n",
      " [[1 2]\n",
      " [2 3]\n",
      " [3 4]]\n",
      "\n",
      "[[1 2]]\n"
     ]
    }
   ],
   "source": [
    "# indexing with boolean list\n",
    "example = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "print(example.shape, '\\n', example)\n",
    "print()\n",
    "print(example[:-1].shape, '\\n', example[:-1])\n",
    "print()\n",
    "print(example[:-1][[True, False, False]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888ed7e-b556-4819-b489-1a1d0cf9c2bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sampling of points from object if they are loaded (don't use at first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d649fc82-ad60-4991-acb2-578316b7fa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance2mask:  {0: 0, 24: 0, 3: 0, 44: 1, 50: 0, 16: 0, 13: 2, 27: 0, 22: 0, 62: 0, 29: 0, 46: 0, 53: 0, 35: 0, 5: 0, 59: 0, 1: 3, 25: 4, 7: 0, 2: 0, 8: 0, 14: 5, 28: 0, 45: 0, 17: 0, 18: 0, 11: 0, 64: 0, 21: 0, 36: 0, 49: 0, 26: 6, 58: 0, 20: 0, 48: 0, 55: 0, 12: 0, 42: 7, 52: 0, 63: 0, 43: 0, 61: 0, 40: 0, 34: 0, 57: 0, 9: 0, 4: 8, 39: 0, 60: 0, 30: 0, 15: 9, 33: 0, 19: 0, 38: 0, 41: 0, 56: 0, 76: 0, 23: 0, 47: 0, 54: 0, 6: 0}\n",
      "num_pointsets:  9\n"
     ]
    }
   ],
   "source": [
    "print('instance2mask: ', instance2mask)\n",
    "print('num_pointsets: ', len(cat))\n",
    "if (with_feats and (not os.path.exists(feats_path) or feats_in is None)) or use_points:\n",
    "    masks = np.array(list(map(lambda l: instance2mask[l] if l in instance2mask.keys() else 0, instances)),\n",
    "                    dtype=np.int32)\n",
    "    print('masks:', masks)\n",
    "    num_pointsets = len(cat)\n",
    "    obj_points = torch.zeros([num_pointsets, npoints, 3]) # (9, 1024, 3)\n",
    "    \n",
    "    for i in range(len(cat)):\n",
    "        obj_pointset = points[np.where(masks == i + 1)[0], :]\n",
    "        \n",
    "        if crop_floor and vocab['object_idx_to_name'][cat[i]].split('\\n')[0] == 'floor':\n",
    "            filter_mask = (obj_pointset[:,0] > min_box[0]) * (obj_pointset[:,0] < max_box[0]) \\\n",
    "            * (obj_pointset[:,1] > min_box[1]) * (obj_pointset[:,1] < max_box[1])\n",
    "            \n",
    "            obj_pointset = obj_pointset[np.where(filter_mask > 0)[0], :]\n",
    "            \n",
    "            print(vocab['object_idx_to_name'][cat[i]].split('\\n')[0], len(obj_pointset))\n",
    "        if len(obj_pointset) >= npoints:\n",
    "            choice = np.random.choice(len(obj_pointset), npoints, replace=False)\n",
    "        else:\n",
    "            choice = np.arange(len(obj_pointset))\n",
    "            # use repetitions to fill some more points\n",
    "            choice2 = np.random.choice(len(obj_pointset), npoints - choice.shape[0], replace=True)\n",
    "            choice = np.concatenate([choice, choice2], 0)\n",
    "            random.shuffle(choice)\n",
    "        \n",
    "        obj_pointset = obj_pointset[choice, :]\n",
    "        obj_pointset = torch.from_numpy(obj_pointset.astype(np.float32))\n",
    "        \n",
    "        if not vae_baseline:\n",
    "            obj_pointset = norm_tensor(obj_pointset, denormalize_box_params(tight_boxes[i]),\n",
    "                                      scale=True, rotation=use_canonical, scale_func=scale_func)\n",
    "        else:\n",
    "            obj_pointset = norm_tensor(obj_pointset, np.asarray(tight_boxes[i]),\n",
    "                                            scale=True, rotation=use_canonical, scale_func=scale_func)\n",
    "    obj_points[i] = obj_pointset\n",
    "else:\n",
    "    obj_points = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7bde1-0b8b-4371-a703-fd9e252bdd73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create Relationship Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8e08f59c-9d71-4475-8a5e-88154023580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel_json:  [[4, 1, 13, 'attached to'], [13, 1, 14, 'standing on'], [14, 4, 13, 'attached to'], [25, 1, 14, 'standing on'], [26, 1, 13, 'attached to'], [42, 1, 14, 'standing on'], [15, 4, 13, 'attached to'], [13, 25, 2, 'right'], [13, 25, 3, 'front'], [13, 42, 2, 'right'], [25, 42, 2, 'right'], [25, 42, 5, 'close by'], [42, 25, 3, 'front'], [14, 13, 7, 'bigger than'], [15, 13, 7, 'bigger than'], [15, 14, 9, 'higher than']]\n",
      "relationship triples:  [[7, 14, 2], [1, 15, 2], [4, 14, 7], [3, 15, 2], [5, 14, 2], [6, 15, 2], [8, 14, 7], [1, 3, 3], [1, 4, 3], [1, 3, 6], [3, 3, 6], [3, 6, 6], [6, 4, 3], [4, 8, 1], [8, 8, 1], [8, 10, 4]]\n"
     ]
    }
   ],
   "source": [
    "triples = []\n",
    "rel_json = relationship_json[scan_id]\n",
    "# print('instance2mask: ', json.dumps(instance2mask, indent=4)) # id : counter (0 if doesn't exist in the scene)\n",
    "print('rel_json: ', rel_json)\n",
    "\n",
    "for r in rel_json: # create relationship triplets from data\n",
    "    if r[0] in instance2mask.keys() and r[1] in instance2mask.keys():\n",
    "        subject = instance2mask[r[0]] - 1\n",
    "        object = instance2mask[r[1]] - 1\n",
    "        predicate = r[2] + 1\n",
    "        if subject >= 0 and object >= 0:\n",
    "            triples.append([subject, predicate, object])\n",
    "    else:\n",
    "        continue\n",
    "print('relationship triples: ', triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07242547-ca02-4163-b4dc-dae2e35466d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add the objects from the selected list of classes of 3DSSG (cat) to the triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "34714d63-e8b6-4639-b123-4d25e7dc13b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: [105, 25, 58, 80, 25, 155, 136, 155, 25, 0, 0, 0, 0]\n",
      "triples:  [[7, 14, 2], [1, 15, 2], [4, 14, 7], [3, 15, 2], [5, 14, 2], [6, 15, 2], [8, 14, 7], [1, 3, 3], [1, 4, 3], [1, 3, 6], [3, 3, 6], [3, 6, 6], [6, 4, 3], [4, 8, 1], [8, 8, 1], [8, 10, 4], [0, 0, 13], [1, 0, 13], [2, 0, 13], [3, 0, 13], [4, 0, 13], [5, 0, 13], [6, 0, 13], [7, 0, 13], [8, 0, 13], [9, 0, 13], [10, 0, 13], [11, 0, 13], [12, 0, 13]]\n"
     ]
    }
   ],
   "source": [
    "print('cat:', cat)\n",
    "print('original triples: ', triples)\n",
    "if use_scene_rels:\n",
    "    # add _scene_ object and _in_scene_ connections\n",
    "    scene_idx = len(cat) # num of instances\n",
    "    for i, ob in enumerate(cat):\n",
    "        triples.append([i, 0, scene_idx])\n",
    "    cat.append(0)\n",
    "    # dummy scene box\n",
    "    tight_boxes.append([-1, -1, -1, -1, -1, -1, -1])\n",
    "print('instances added triples: ', triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ac27d-32c5-438d-9afe-0e2c947d8607",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "95ee780d-afe9-47e8-a56f-c70ec3dd7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "if use_points:\n",
    "    output['scene'] = points\n",
    "\n",
    "if with_feats and (not os.path.exists(feats_path) or feats_in is None) and atlas is not None:\n",
    "    pf = torch.from_numpy(np.array(list(obj_points.numpy()), dtype=np.float32)).float().cuda().transpose(1,2)\n",
    "    with torch.no_grad():\n",
    "        feats = atlas.encoder(pf).detach().cpu().numpy()\n",
    "\n",
    "    feats_out = {}\n",
    "    feats_out['feats'] = feats\n",
    "    feats_out['instance_order'] = instances_order\n",
    "    feats_in = list(feats)\n",
    "\n",
    "    assert path2atlas is not None\n",
    "    path = os.path.join(feats_path)\n",
    "    if recompute_feats:\n",
    "        path = path[:-3]\n",
    "\n",
    "    pickle.dump(feats_out, open(path, 'wb'))\n",
    "\n",
    "# prepare outputs\n",
    "output['encoder'] = {}\n",
    "output['encoder']['objs'] = cat\n",
    "output['encoder']['triples'] = triples\n",
    "output['encoder']['boxes'] = tight_boxes\n",
    "if use_points:\n",
    "    output['encoder']['points'] = list(obj_points.numpy())\n",
    "\n",
    "if with_feats:\n",
    "    output['encoder']['feats'] = feats_in\n",
    "\n",
    "output['manipulate'] = {}\n",
    "if not with_changes:\n",
    "    output['manipulate']['type'] = 'none'\n",
    "    output['decoder'] = copy.deepcopy(output['encoder'])\n",
    "else: # manipulation\n",
    "    if with_changes:\n",
    "        output['manipulate']['type'] = ['relationship', 'addition', 'none'][\n",
    "            np.random.randint(3)]  # removal is trivial - so only addition and rel change\n",
    "    else:\n",
    "        output['manipulate']['type'] = 'none'\n",
    "    output['decoder'] = copy.deepcopy(output['encoder'])\n",
    "    if output['manipulate']['type'] == 'addition':\n",
    "        node_id = remove_node_and_relationship(output['encoder'])\n",
    "        if node_id >= 0:\n",
    "            output['manipulate']['added'] = node_id\n",
    "        else:\n",
    "            output['manipulate']['type'] = 'none'\n",
    "    elif output['manipulate']['type'] == 'relationship':\n",
    "        rel, pair, suc = modify_relship(output['decoder'])\n",
    "        if suc:\n",
    "            output['manipulate']['relship'] = (rel, pair)\n",
    "        else:\n",
    "            output['manipulate']['type'] = 'none'\n",
    "\n",
    "# torchify\n",
    "output['encoder']['objs'] = torch.from_numpy(np.array(output['encoder']['objs'], dtype=np.int64))\n",
    "output['encoder']['triples'] = torch.from_numpy(np.array(output['encoder']['triples'], dtype=np.int64))\n",
    "output['encoder']['boxes'] = torch.from_numpy(np.array(output['encoder']['boxes'], dtype=np.float32))\n",
    "if use_points:\n",
    "    output['encoder']['points'] = torch.from_numpy(np.array(output['encoder']['points'], dtype=np.float32))\n",
    "if with_feats:\n",
    "    output['encoder']['feats'] = torch.from_numpy(np.array(output['encoder']['feats'], dtype=np.float32))\n",
    "\n",
    "output['decoder']['objs'] = torch.from_numpy(np.array(output['decoder']['objs'], dtype=np.int64))\n",
    "output['decoder']['triples'] = torch.from_numpy(np.array(output['decoder']['triples'], dtype=np.int64))\n",
    "output['decoder']['boxes'] = torch.from_numpy(np.array(output['decoder']['boxes'], dtype=np.float32))\n",
    "if use_points:\n",
    "    output['decoder']['points'] = torch.from_numpy(np.array(output['decoder']['points'], dtype=np.float32))\n",
    "if with_feats:\n",
    "    output['decoder']['feats'] = torch.from_numpy(np.array(output['decoder']['feats'], dtype=np.float32))\n",
    "\n",
    "output['scan_id'] = scan_id_no_split\n",
    "output['split_id'] = scan_id.split('_')[1]\n",
    "output['instance_id'] = instances_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c7307161-7d2b-48ae-8885-f4e78d33e7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['encoder', 'manipulate', 'decoder', 'scan_id', 'split_id', 'instance_id'])\n",
      "\n",
      "{'encoder': {'objs': tensor([105,  25,  58,  80,  25, 155, 136, 155,  25,   0,   0,   0,   0,   0]), 'triples': tensor([[ 7, 14,  2],\n",
      "        [ 1, 15,  2],\n",
      "        [ 4, 14,  7],\n",
      "        [ 3, 15,  2],\n",
      "        [ 5, 14,  2],\n",
      "        [ 6, 15,  2],\n",
      "        [ 8, 14,  7],\n",
      "        [ 1,  3,  3],\n",
      "        [ 1,  4,  3],\n",
      "        [ 1,  3,  6],\n",
      "        [ 3,  3,  6],\n",
      "        [ 3,  6,  6],\n",
      "        [ 6,  4,  3],\n",
      "        [ 4,  8,  1],\n",
      "        [ 8,  8,  1],\n",
      "        [ 8, 10,  4],\n",
      "        [ 0,  0, 13],\n",
      "        [ 1,  0, 13],\n",
      "        [ 2,  0, 13],\n",
      "        [ 3,  0, 13],\n",
      "        [ 4,  0, 13],\n",
      "        [ 5,  0, 13],\n",
      "        [ 6,  0, 13],\n",
      "        [ 7,  0, 13],\n",
      "        [ 8,  0, 13],\n",
      "        [ 9,  0, 13],\n",
      "        [10,  0, 13],\n",
      "        [11,  0, 13],\n",
      "        [12,  0, 13]]), 'boxes': tensor([[-1.6146, -1.4903, -2.0074,  2.6636,  2.0038, -1.5900,  3.5464],\n",
      "        [-1.9436, -1.1287, -0.1898,  5.0135,  0.4374, -2.0931, 12.3861],\n",
      "        [ 5.3240, 12.6525, -2.5450,  1.7092, -0.7194, -3.8047,  5.0023],\n",
      "        [-1.5513, -1.2321,  0.1676,  3.7657,  1.9072, -1.8117, 10.8262],\n",
      "        [-1.8695,  2.3699, -1.1823,  1.6974,  2.7596,  2.5052, 21.4339],\n",
      "        [-1.7011, -0.7739,  1.3098,  6.6460,  3.3572, -1.2050, -0.8215],\n",
      "        [-1.5231, -1.5585, -1.8478,  3.4352,  1.4318, -3.0563, -3.1094],\n",
      "        [-1.9264,  3.3177,  5.9582,  2.0529,  2.8746,  1.6531,  3.1304],\n",
      "        [-2.0429,  2.0913, -0.9470,  1.7122,  2.4449,  4.8972, 21.6419],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]), 'feats': tensor([[0.4360, 1.1080, 0.0000,  ..., 0.0000, 0.0280, 0.4731],\n",
      "        [0.4360, 1.1080, 0.0000,  ..., 0.0000, 0.0280, 0.4731],\n",
      "        [0.4360, 1.1080, 0.0000,  ..., 0.0000, 0.0280, 0.4731],\n",
      "        ...,\n",
      "        [0.4360, 1.1080, 0.0000,  ..., 0.0000, 0.0280, 0.4731],\n",
      "        [0.3362, 0.2669, 0.1163,  ..., 0.0000, 0.2088, 0.2297],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])}, 'manipulate': {'type': 'none'}, 'decoder': {'objs': tensor([105,  25,  58,  80,  25, 155, 136, 155,  25,   0,   0,   0,   0,   0]), 'triples': tensor([[ 7, 14,  2],\n",
      "        [ 1, 15,  2],\n",
      "        [ 4, 14,  7],\n",
      "        [ 3, 15,  2],\n",
      "        [ 5, 14,  2],\n",
      "        [ 6, 15,  2],\n",
      "        [ 8, 14,  7],\n",
      "        [ 1,  3,  3],\n",
      "        [ 1,  4,  3],\n",
      "        [ 1,  3,  6],\n",
      "        [ 3,  3,  6],\n",
      "        [ 3,  6,  6],\n",
      "        [ 6,  4,  3],\n",
      "        [ 4,  8,  1],\n",
      "        [ 8,  8,  1],\n",
      "        [ 8, 10,  4],\n",
      "        [ 0,  0, 13],\n",
      "        [ 1,  0, 13],\n",
      "        [ 2,  0, 13],\n",
      "        [ 3,  0, 13],\n",
      "        [ 4,  0, 13],\n",
      "        [ 5,  0, 13],\n",
      "        [ 6,  0, 13],\n",
      "        [ 7,  0, 13],\n",
      "        [ 8,  0, 13],\n",
      "        [ 9,  0, 13],\n",
      "        [10,  0, 13],\n",
      "        [11,  0, 13],\n",
      "        [12,  0, 13]]), 'boxes': tensor([[-1.6146, -1.4903, -2.0074,  2.6636,  2.0038, -1.5900,  3.5464],\n",
      "        [-1.9436, -1.1287, -0.1898,  5.0135,  0.4374, -2.0931, 12.3861],\n",
      "        [ 5.3240, 12.6525, -2.5450,  1.7092, -0.7194, -3.8047,  5.0023],\n",
      "        [-1.5513, -1.2321,  0.1676,  3.7657,  1.9072, -1.8117, 10.8262],\n",
      "        [-1.8695,  2.3699, -1.1823,  1.6974,  2.7596,  2.5052, 21.4339],\n",
      "        [-1.7011, -0.7739,  1.3098,  6.6460,  3.3572, -1.2050, -0.8215],\n",
      "        [-1.5231, -1.5585, -1.8478,  3.4352,  1.4318, -3.0563, -3.1094],\n",
      "        [-1.9264,  3.3177,  5.9582,  2.0529,  2.8746,  1.6531,  3.1304],\n",
      "        [-2.0429,  2.0913, -0.9470,  1.7122,  2.4449,  4.8972, 21.6419],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]), 'feats': tensor([[0.4360, 1.1080, 0.0000,  ..., 0.0000, 0.0280, 0.4731],\n",
      "        [0.4360, 1.1080, 0.0000,  ..., 0.0000, 0.0280, 0.4731],\n",
      "        [0.4360, 1.1080, 0.0000,  ..., 0.0000, 0.0280, 0.4731],\n",
      "        ...,\n",
      "        [0.4360, 1.1080, 0.0000,  ..., 0.0000, 0.0280, 0.4731],\n",
      "        [0.3362, 0.2669, 0.1163,  ..., 0.0000, 0.2088, 0.2297],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])}, 'scan_id': 'f62fd5fd-9a3f-2f44-883a-1e5cf819608e', 'split_id': '1', 'instance_id': [44, 13, 1, 25, 14, 26, 42, 4, 15]}\n"
     ]
    }
   ],
   "source": [
    "print(output.keys())\n",
    "print()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c75ed2-abf6-4433-ae81-0d0472a923a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Collate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "300463e1-8eb8-4448-89a3-99f7722898ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_vaegan(batch, use_points=False):\n",
    "    \"\"\"\n",
    "    Collate function to be used when wrapping a RIODatasetSceneGraph in a\n",
    "    DataLoader. Returns a dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    out['scene_points'] = []\n",
    "    out['scan_id'] = []\n",
    "    out['instance_id'] = []\n",
    "    out['split_id'] = []\n",
    "\n",
    "    out['missing_nodes'] = []\n",
    "    out['missing_nodes_decoder'] = []\n",
    "    out['manipulated_nodes'] = []\n",
    "    global_node_id = 0\n",
    "    global_dec_id = 0\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "        if batch[i] == -1:\n",
    "            return -1\n",
    "        # notice only works with single batches\n",
    "        out['scan_id'].append(batch[i]['scan_id'])\n",
    "        out['instance_id'].append(batch[i]['instance_id'])\n",
    "        out['split_id'].append(batch[i]['split_id'])\n",
    "\n",
    "        if batch[i]['manipulate']['type'] == 'addition':\n",
    "            out['missing_nodes'].append(global_node_id + batch[i]['manipulate']['added'])\n",
    "            out['missing_nodes_decoder'].append(global_dec_id + batch[i]['manipulate']['added'])\n",
    "        elif batch[i]['manipulate']['type'] == 'relationship':\n",
    "            rel, (sub, obj) = batch[i]['manipulate']['relship']\n",
    "            out['manipulated_nodes'].append(global_dec_id + sub)\n",
    "            out['manipulated_nodes'].append(global_dec_id + obj)\n",
    "\n",
    "        if 'scene' in batch[i]:\n",
    "            out['scene_points'].append(batch[i]['scene'])\n",
    "\n",
    "        global_node_id += len(batch[i]['encoder']['objs'])\n",
    "        global_dec_id += len(batch[i]['decoder']['objs'])\n",
    "\n",
    "    for key in ['encoder', 'decoder']:\n",
    "        all_objs, all_boxes, all_triples = [], [], []\n",
    "        all_obj_to_scene, all_triple_to_scene = [], []\n",
    "        all_points = []\n",
    "        all_feats = []\n",
    "\n",
    "        obj_offset = 0\n",
    "\n",
    "        for i in range(len(batch)):\n",
    "            if batch[i] == -1:\n",
    "                print('this should not happen')\n",
    "                continue\n",
    "            (objs, triples, boxes) = batch[i][key]['objs'], batch[i][key]['triples'], batch[i][key]['boxes']\n",
    "\n",
    "            if 'points' in batch[i][key]:\n",
    "                all_points.append(batch[i][key]['points'])\n",
    "            if 'feats' in batch[i][key]:\n",
    "                all_feats.append(batch[i][key]['feats'])\n",
    "\n",
    "            num_objs, num_triples = objs.size(0), triples.size(0)\n",
    "\n",
    "            all_objs.append(objs)\n",
    "            all_boxes.append(boxes)\n",
    "\n",
    "            if triples.dim() > 1:\n",
    "                triples = triples.clone()\n",
    "                triples[:, 0] += obj_offset\n",
    "                triples[:, 2] += obj_offset\n",
    "\n",
    "                all_triples.append(triples)\n",
    "                all_triple_to_scene.append(torch.LongTensor(num_triples).fill_(i))\n",
    "\n",
    "            all_obj_to_scene.append(torch.LongTensor(num_objs).fill_(i))\n",
    "\n",
    "            obj_offset += num_objs\n",
    "\n",
    "        all_objs = torch.cat(all_objs)\n",
    "        all_boxes = torch.cat(all_boxes)\n",
    "\n",
    "        all_obj_to_scene = torch.cat(all_obj_to_scene)\n",
    "\n",
    "        if len(all_triples) > 0:\n",
    "            all_triples = torch.cat(all_triples)\n",
    "            all_triple_to_scene = torch.cat(all_triple_to_scene)\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "        outputs = {'objs': all_objs,\n",
    "                   'tripltes': all_triples,\n",
    "                   'boxes': all_boxes,\n",
    "                   'obj_to_scene': all_obj_to_scene,\n",
    "                   'tiple_to_scene': all_triple_to_scene}\n",
    "\n",
    "        if len(all_points) > 0:\n",
    "            all_points = torch.cat(all_points)\n",
    "            outputs['points'] = all_points\n",
    "\n",
    "        if len(all_feats) > 0:\n",
    "            all_feats = torch.cat(all_feats)\n",
    "            outputs['feats'] = all_feats\n",
    "        out[key] = outputs\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "99167850-fea3-4bfb-a04d-eb73a1359b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_vaegan_points(batch):\n",
    "    \"\"\" Wrapper of the function collate_fn_vaegan to make it also return points\n",
    "    \"\"\"\n",
    "    return collate_fn_vaegan(batch, use_points=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0fa440-53d1-42c8-9339-d32565fd65f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
